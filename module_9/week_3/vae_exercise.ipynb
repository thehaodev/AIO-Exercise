{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U9AeB4wgKBL1"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from tqdm import tqdm\n",
        "from torchsummary import summary\n",
        "from torchvision import transforms, datasets\n",
        "from torch.utils.data import DataLoader, random_split"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)"
      ],
      "metadata": {
        "id": "6RXsrkB7Lenw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameters\n",
        "batch_size = 256\n",
        "img_size = 28  # original image size is 28x28\n",
        "channels = 1    # grayscale image\n",
        "latent_dim = 2\n",
        "num_epochs = 500  # training epochs\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((img_size, img_size)),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "dataset = datasets.MNIST(\n",
        "    root=\"./data/\",  # Data storage directory\n",
        "    train=True,\n",
        "    transform=transform,\n",
        "    download=True,\n",
        ")"
      ],
      "metadata": {
        "id": "67qDh6fVLf9j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split dataset into training (80%) and validation (20%)\n",
        "train_size = int(0.8 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "print(f\"Training samples: {len(train_dataset)}, Validation samples: {len(val_dataset)}\")\n",
        "\n",
        "# Create DataLoaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=2)"
      ],
      "metadata": {
        "id": "7rZiPm7SLjvd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Define the Variational Autoencoder (VAE) in PyTorch\n",
        "class VAE(nn.Module):\n",
        "    def __init__(self, channels, latent_dim):\n",
        "        super(VAE, self).__init__()\n",
        "        # Encoder\n",
        "        self.conv1 = nn.Conv2d(channels, 16, kernel_size=3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=2, padding=1)\n",
        "        self.conv3 = nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=1)\n",
        "        self.flatten_dim = 64 * 7 * 7\n",
        "        self.fc_mu = nn.Linear(self.flatten_dim, latent_dim)\n",
        "        self.fc_logvar = nn.Linear(self.flatten_dim, latent_dim)\n",
        "\n",
        "        # Decoder\n",
        "        self.fc_decode = nn.Linear(latent_dim, self.flatten_dim)\n",
        "        self.deconv1 = nn.ConvTranspose2d(64, 32, kernel_size=3, stride=2, padding=1, output_padding=1)\n",
        "        self.deconv2 = nn.ConvTranspose2d(32, 16, kernel_size=3, stride=2, padding=1, output_padding=1)\n",
        "        self.conv_out = nn.Conv2d(16, channels, kernel_size=3, padding=1)\n",
        "\n",
        "    def encode(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = F.relu(self.conv3(x))\n",
        "        x = x.view(-1, self.flatten_dim)\n",
        "        mu = self.fc_mu(x)\n",
        "        logvar = self.fc_logvar(x)\n",
        "        return mu, logvar\n",
        "\n",
        "    def reparameterize(self, mu, logvar):\n",
        "        std = torch.exp(0.5 * logvar)\n",
        "        eps = torch.randn_like(std)\n",
        "        return mu + eps * std\n",
        "\n",
        "    def decode(self, z):\n",
        "        x = F.relu(self.fc_decode(z))\n",
        "        x = x.view(-1, 64, 7, 7)\n",
        "        x = F.relu(self.deconv1(x))\n",
        "        x = F.relu(self.deconv2(x))\n",
        "        recon_x = self.conv_out(x)\n",
        "        return recon_x\n",
        "\n",
        "    def forward(self, x):\n",
        "        mu, logvar = self.encode(x)\n",
        "        z = self.reparameterize(mu, logvar)\n",
        "        recon_x = self.decode(z)\n",
        "        return recon_x, mu, logvar"
      ],
      "metadata": {
        "id": "Dpual0bML3cC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def loss_function(recon_x, x, mu, log_var, B=1000):\n",
        "    # Flatten tensors for MSE calculation\n",
        "    recon_x_flat = recon_x.view(recon_x.size(0), -1)\n",
        "    x_flat = x.view(x.size(0), -1)\n",
        "\n",
        "    # Calculate MSE (per element average)\n",
        "    mse_out = F.mse_loss(recon_x_flat, x_flat, reduction='mean')\n",
        "\n",
        "    # Scale by input dimensions\n",
        "    reconstruction_loss = mse_out * x.shape[1] * x.shape[2] * x.shape[3]\n",
        "\n",
        "    # Calculate KL divergence\n",
        "    kl_loss = -0.5 * torch.sum(1 + log_var - mu.pow(2) - log_var.exp(), axis=1)\n",
        "\n",
        "    # Compute final loss (adding reconstruction_loss + kl_loss)\n",
        "    total_loss = B * reconstruction_loss + torch.mean(kl_loss)\n",
        "\n",
        "    return total_loss, reconstruction_loss, torch.mean(kl_loss)"
      ],
      "metadata": {
        "id": "3sy2qS-IL4eK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create model, optimizer, etc.\n",
        "model = VAE(channels, latent_dim).to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-5)"
      ],
      "metadata": {
        "id": "bg6r938aMNnD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from datetime import datetime\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Create a log directory if it doesn't exist\n",
        "log_dir = \"logs\"\n",
        "os.makedirs(log_dir, exist_ok=True)\n",
        "\n",
        "# Create a log file with timestamp\n",
        "timestamp = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
        "log_file = os.path.join(log_dir, f'training_log_{timestamp}.txt')\n",
        "\n",
        "# Open the log file\n",
        "with open(log_file, \"w\") as f:\n",
        "    f.write(f'Training started at {datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")}\\n')\n",
        "    f.write(f'Model: VAE with latent_dim={latent_dim}\\n')\n",
        "    f.write(f'Batch size: {batch_size}, Image size: {img_size}\\n')\n",
        "    f.write(f'Total epochs: {num_epochs}\\n')\n",
        "    f.write('Epoch,Avg_Loss,Recon_Loss,KL_Loss\\n')\n",
        "\n",
        "# Training loop with logging\n",
        "model.train()\n",
        "train_loss = 0.0\n",
        "for epoch in range(num_epochs):\n",
        "    epoch_bar = tqdm(train_loader, desc=f'Epoch {epoch + 1}/{num_epochs}', leave=False)\n",
        "    for data in epoch_bar:\n",
        "        optimizer.zero_grad()\n",
        "        recon_batch, mu, log_var = model(data.to(device))\n",
        "        loss, reconstruction_loss, kl_loss = loss_function(recon_batch, data, mu, log_var)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "\n",
        "# Calculate average loss\n",
        "avg_loss = train_loss / len(train_loader.dataset)\n",
        "\n",
        "# Print epoch summary\n",
        "print(f'Epoch [{epoch + 1}/{num_epochs}] Loss per sample: {avg_loss:.4f} '\n",
        "      f'Recon Loss: {reconstruction_loss.item():.4f}, KL Loss: {kl_loss.item():.4f}')\n",
        "\n",
        "# Save to log file\n",
        "with open(log_file, \"a\") as f:\n",
        "    f.write(f'{epoch + 1},{avg_loss:.4f},{reconstruction_loss.item():.4f},{kl_loss.item():.4f}\\n')"
      ],
      "metadata": {
        "id": "FI5dl82RMOLM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# After training, visualize the reconstruction on validation images\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    data_iter = iter(val_loader)\n",
        "    images, _ = next(data_iter)\n",
        "    images = images.to(device)\n",
        "    recon_images, _, _ = model(images)"
      ],
      "metadata": {
        "id": "efPgTE-DMgfn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plot original and reconstructed images side by side\n",
        "n = 10  # number of images to display\n",
        "plt.figure(figsize=(20, 4))\n",
        "\n",
        "for i in range(n):\n",
        "    # Original image: (C,H,W) -> (H,W,C)\n",
        "    orig = images[i].cpu().permute(1, 2, 0).numpy()\n",
        "    recon = recon_images[i].cpu().permute(1, 2, 0).numpy()\n",
        "\n",
        "    ax = plt.subplot(2, n, i + 1)\n",
        "    plt.imshow(orig)\n",
        "    plt.title(\"Original\")\n",
        "    plt.axis('off')\n",
        "\n",
        "    ax = plt.subplot(2, n, i + 1 + n)\n",
        "    plt.imshow(recon)\n",
        "    plt.title(\"Reconstructed\")\n",
        "    plt.axis('off')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "skwPGdPNMg23"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}