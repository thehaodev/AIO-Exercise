{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CK6uADNl6JNf"
      },
      "outputs": [],
      "source": [
        "!pip install kaggle"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"andrewmvd/dog-and-cat-detection\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ],
      "metadata": {
        "id": "y7YBKp1LunQU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ImageDataset(Dataset):\n",
        "    def __init__(self, annotations_dir, image_dir, transform=None):\n",
        "        self.annotations_dir = annotations_dir\n",
        "        self.image_dir = image_dir\n",
        "        self.transform = transform\n",
        "        self.image_files = self.filter_images_with_multiple_objects()\n",
        "\n",
        "    def filter_images_with_multiple_objects(self):\n",
        "        valid_image_files = []\n",
        "        for f in os.listdir(self.image_dir):\n",
        "            if os.path.isfile(os.path.join(self.image_dir, f)):\n",
        "                annotation_name = os.path.splitext(f)[0] + \".xml\"\n",
        "                annotation_path = os.path.join(self.annotations_dir, annotation_name)\n",
        "\n",
        "                if self.count_objects_in_annotation(annotation_path) == 1:\n",
        "                    valid_image_files.append(f)\n",
        "        return valid_image_files\n",
        "\n",
        "    def count_objects_in_annotation(self, annotation_path):\n",
        "        try:\n",
        "            tree = ET.parse(annotation_path)\n",
        "            root = tree.getroot()\n",
        "            count = 0\n",
        "            for obj in root.findall('object'):\n",
        "                count += 1\n",
        "            return count\n",
        "        except FileNotFoundError:\n",
        "            return 0\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_files)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_name = self.image_files[idx]\n",
        "        img_path = os.path.join(self.image_dir, img_name)\n",
        "\n",
        "        image = Image.open(img_path).convert(\"RGB\")\n",
        "        annotation_name = os.path.splitext(img_name)[0] + \".xml\"\n",
        "        annotation_path = os.path.join(self.annotations_dir, annotation_name)\n",
        "\n",
        "        label, bbox = self.parse_annotation(annotation_path)\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label, bbox\n",
        "\n",
        "    def parse_annotation(self, annotation_path):\n",
        "        tree = ET.parse(annotation_path)\n",
        "        root = tree.getroot()\n",
        "\n",
        "        image_width = int(root.find('size/width').text)\n",
        "        image_height = int(root.find('size/height').text)\n",
        "\n",
        "        bbox = None\n",
        "        label = None\n",
        "\n",
        "        for obj in root.findall('object'):\n",
        "            label = obj.find('name').text\n",
        "            # Lấy bounding box tọa độ\n",
        "            xmin = int(obj.find('bndbox/xmin').text)\n",
        "            ymin = int(obj.find('bndbox/ymin').text)\n",
        "            xmax = int(obj.find('bndbox/xmax').text)\n",
        "            ymax = int(obj.find('bndbox/ymax').text)\n",
        "\n",
        "            # Chuyển đổi tọa độ bbox về tỷ lệ [0, 1]\n",
        "            bbox = [\n",
        "                xmin / image_width,\n",
        "                ymin / image_height,\n",
        "                xmax / image_width,\n",
        "                ymax / image_height,\n",
        "            ]\n",
        "\n",
        "            break  # Lấy nhãn của đối tượng đầu tiên\n",
        "\n",
        "        # Chuyển đổi nhãn thành số (0 cho mèo, 1 cho chó)\n",
        "        label_num = 0 if label == 'cat' else 1 if label == 'dog' else -1\n",
        "\n",
        "        return label_num, torch.tensor(bbox, dtype=torch.float32)"
      ],
      "metadata": {
        "id": "WbB2c7h3urlf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Thư mục dữ liệu\n",
        "annotations_dir = os.path.join(data_dir, 'annotations')\n",
        "image_dir = os.path.join(data_dir, 'images')\n",
        "\n",
        "# Lấy danh sách tệp ảnh và tạo DataFrame giả để phân chia dữ liệu\n",
        "image_files = [f for f in os.listdir(image_dir) if os.path.isfile(os.path.join(image_dir, f))]\n",
        "df = pd.DataFrame({'image_name': image_files})\n",
        "\n",
        "# Phân chia dữ liệu\n",
        "train_df, val_df = train_test_split(df, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "JKRU7A1RvBuR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Chuyển đổi\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Dataset\n",
        "train_dataset = ImageDataset(annotations_dir, image_dir, transform=transform)\n",
        "val_dataset = ImageDataset(annotations_dir, image_dir, transform=transform)"
      ],
      "metadata": {
        "id": "8g-wWxZsvWi7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tạo danh sách tệp ảnh cho train và val\n",
        "train_dataset.image_files = [f for f in train_dataset.image_files if f in train_df['image_name'].values]\n",
        "val_dataset.image_files = [f for f in val_dataset.image_files if f in val_df['image_name'].values]\n",
        "\n",
        "# Dataloader\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)"
      ],
      "metadata": {
        "id": "GsHOvcU8vZqE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mô hình với hai đầu\n",
        "class TwoHeadedModel(nn.Module):\n",
        "    def __init__(self, num_classes=2):\n",
        "        super(TwoHeadedModel, self).__init__()\n",
        "        self.base_model = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)\n",
        "        self.num_ftrs = self.base_model.fc.in_features\n",
        "\n",
        "        # Loại bỏ lớp fully connected gốc\n",
        "        self.base_model.fc = nn.Identity()\n",
        "\n",
        "        # Đầu phân loại\n",
        "        self.classifier = nn.Linear(self.num_ftrs, num_classes)\n",
        "\n",
        "        # Đầu hồi quy bounding box\n",
        "        self.regressor = nn.Linear(self.num_ftrs, 4)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.base_model(x)\n",
        "        class_logits = self.classifier(x)\n",
        "        bbox_coords = torch.sigmoid(self.regressor(x))\n",
        "        return class_logits, bbox_coords"
      ],
      "metadata": {
        "id": "P4k0IP5IvmJK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = TwoHeadedModel()\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "criterion_class = nn.CrossEntropyLoss()\n",
        "criterion_bbox = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "O7Q3iZRrvp__"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Vòng lặp huấn luyện\n",
        "num_epochs = 10\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    for batch_idx, (data, targets, bboxes) in enumerate(train_loader):\n",
        "        data = data.to(device)\n",
        "        targets = targets.to(device)\n",
        "        bboxes = bboxes.to(device)\n",
        "\n",
        "        scores, pred_bboxes = model(data)\n",
        "        loss_class = criterion_class(scores, targets)\n",
        "        loss_bbox = criterion_bbox(pred_bboxes, bboxes)\n",
        "\n",
        "        loss = loss_class + loss_bbox  # Kết hợp các mất mát\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    # Xác thực\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        total_loss_bbox = 0\n",
        "        total_samples = 0\n",
        "\n",
        "        for data, targets, bboxes in val_loader:\n",
        "            data = data.to(device)\n",
        "            targets = targets.to(device)\n",
        "            bboxes = bboxes.to(device)\n",
        "\n",
        "            scores, pred_bboxes = model(data)\n",
        "            predictions = scores.argmax(dim=1)\n",
        "            correct += (predictions == targets).sum().item()\n",
        "            total += targets.size(0)\n",
        "\n",
        "            total_loss_bbox += criterion_bbox(pred_bboxes, bboxes).item() * data.size(0)\n",
        "            total_samples += data.size(0)\n",
        "\n",
        "        avg_loss_bbox = total_loss_bbox / total_samples\n",
        "\n",
        "        print(f'Epoch {epoch + 1}/{num_epochs}, Validation Accuracy: {float(correct) / float(total) * 100:.2f}%, '\n",
        "              f'Avg. Bbox Loss: {avg_loss_bbox:.4f}')\n"
      ],
      "metadata": {
        "id": "rKdtAKknwOy7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}