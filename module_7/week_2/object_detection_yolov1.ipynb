{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BuXlI28C0YZy"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "import cv2\n",
        "from glob import glob\n",
        "from tqdm import tqdm\n",
        "from collections import Counter\n",
        "\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomVOCdataset(torchvision.datasets.VOCDetection):\n",
        "    def init_config_yolo(self, class_mapping, S=7, B=2, C=20, custom_transforms=None):\n",
        "        # Khởi tạo các tham số cấu hình YOLO cụ thể.\n",
        "        self.S = S  # Kích thước lưới S x S\n",
        "        self.B = B  # Số lượng hộp dự đoán\n",
        "        self.C = C  # Số lượng lớp\n",
        "        self.class_mapping = class_mapping  # Ánh xạ tên lớp sang chỉ số lớp\n",
        "        self.custom_transforms = custom_transforms\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        # Lấy hình ảnh và nhãn từ tập VOC.\n",
        "        image, target = super(CustomVOCdataset, self).__getitem__(index)\n",
        "        img_width, img_height = image.size\n",
        "\n",
        "        # Chuyển đổi nhãn thành định dạng YOLO.\n",
        "        boxes = convert_to_yolo_format(target, img_width, img_height, self.class_mapping)\n",
        "\n",
        "        # Nếu có các phép biến đổi tùy chỉnh, áp dụng chúng.\n",
        "        just_boxes = boxes[:, 1:]  # Bỏ chỉ số lớp\n",
        "        labels = boxes[:, 0]        # Chỉ số lớp\n",
        "\n",
        "        if self.custom_transforms:\n",
        "            sample = {\n",
        "                'image': np.array(image),\n",
        "                'boxes': just_boxes,\n",
        "                'labels': labels\n",
        "            }\n",
        "            sample = self.custom_transforms(**sample)\n",
        "            image = sample['image']\n",
        "            boxes = sample['boxes']\n",
        "            labels = sample['labels']\n",
        "\n",
        "        # Tạo một ma trận nhãn trống cho mục tiêu YOLO.\n",
        "        label_matrix = torch.zeros((self.S, self.S, self.C + 5 * self.B))\n",
        "\n",
        "        # Chuyển đổi sang dạng tensor.\n",
        "        boxes = torch.tensor(boxes, dtype=torch.float32)\n",
        "        labels = torch.tensor(labels, dtype=torch.float32)\n",
        "        image = torch.tensor(image, dtype=torch.float32)\n",
        "\n",
        "        # Lặp qua từng hộp bao và định dạng cho YOLO.\n",
        "        for box, class_label in zip(boxes, labels):\n",
        "            x, width, height = box.tolist()\n",
        "            class_label = int(class_label)\n",
        "\n",
        "            # Tính toán ô lưới (i, j) mà hộp này thuộc về.\n",
        "            i = int(self.S * y)  # Cần thêm y vào đây\n",
        "            j = int(self.S * x)\n",
        "\n",
        "            # Tính toán chiều rộng và chiều cao của hộp tương đối với ô lưới.\n",
        "            width_cell, height_cell = width * self.S, height * self.S\n",
        "\n",
        "            # Nếu không có đối tượng nào được tìm thấy trong ô lưới này.\n",
        "            if label_matrix[i, j, 20] == 0:  # Mark as an object\n",
        "                label_matrix[i, j, 20] = 1\n",
        "\n",
        "            # Lưu tọa độ của hộp bao dưới dạng khoảng cách từ biên tế ô lưới.\n",
        "            box_coordinates = torch.tensor([x_cell, y_cell, width_cell, height_cell])\n",
        "            label_matrix[i, j, 21:25] = box_coordinates\n",
        "\n",
        "            # Lưu mã hóa one-hot cho lớp.\n",
        "            label_matrix[i, j, class_label] = 1\n",
        "\n",
        "        return image, label_matrix"
      ],
      "metadata": {
        "id": "pvjpMCRz0daH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_to_yolo_format(target, img_width, img_height, class_mapping):\n",
        "    \"\"\"\n",
        "    Convert annotation data from VOC format to YOLO format.\n",
        "\n",
        "    Parameters:\n",
        "    target (dict): Annotation data from VOCDetection dataset.\n",
        "    img_width (int): Width of the original image.\n",
        "    img_height (int): Height of the original image.\n",
        "    class_mapping (dict): Mapping from class names to integer IDs.\n",
        "\n",
        "    Returns:\n",
        "    torch.Tensor: Tensor of shape [N, 5] for N bounding boxes,\n",
        "    each with [class_id, x_center, y_center, width, height].\n",
        "    \"\"\"\n",
        "    # Extract the list of annotations from the target dictionary.\n",
        "    annotations = target['annotation']['object']\n",
        "\n",
        "    # Get the real width and height of the image from the annotation.\n",
        "    real_width = int(target['annotation']['size']['width'])\n",
        "    real_height = int(target['annotation']['size']['height'])\n",
        "\n",
        "    # Ensure that annotations is a list, even if there's only one object.\n",
        "    if not isinstance(annotations, list):\n",
        "        annotations = [annotations]\n",
        "\n",
        "    # Initialize an empty list to store the converted bounding boxes.\n",
        "    boxes = []\n",
        "\n",
        "    # Loop through each annotation and convert it to YOLO format.\n",
        "    for anno in annotations:\n",
        "        xmin = int(anno['bndbox']['xmin']) / real_width\n",
        "        xmax = int(anno['bndbox']['xmax']) / real_width\n",
        "        ymin = int(anno['bndbox']['ymin']) / real_height\n",
        "        ymax = int(anno['bndbox']['ymax']) / real_height\n",
        "\n",
        "        # Calculate the center coordinates, width, and height of the bounding box.\n",
        "        x_center = (xmin + xmax) / 2\n",
        "        y_center = (ymin + ymax) / 2\n",
        "        width = xmax - xmin\n",
        "        height = ymax - ymin\n",
        "\n",
        "        # Retrieve the class name from the annotation and map it to an integer ID.\n",
        "        class_name = anno['name']\n",
        "        class_id = class_mapping[class_name] if class_name in class_mapping else -1\n",
        "\n",
        "        # Append the YOLO formatted bounding box to the list.\n",
        "        boxes.append([class_id, x_center, y_center, width, height])\n",
        "\n",
        "    # Convert the list of boxes to a torch tensor.\n",
        "    return torch.tensor(boxes)"
      ],
      "metadata": {
        "id": "fxQ_SWal1PPP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def intersection_over_union(boxes_preds, boxes_labels, box_format=\"midpoint\"):\n",
        "    \"\"\"\n",
        "    Calculate the Intersection over Union (IoU) between bounding boxes.\n",
        "\n",
        "    Parameters:\n",
        "    boxes_preds (tensor): Predicted bounding boxes (BATCH_SIZE, 4).\n",
        "    boxes_labels (tensor): Ground truth bounding boxes (BATCH_SIZE, 4).\n",
        "    box_format (str): Box format, can be \"midpoint\" or \"corners\".\n",
        "\n",
        "    Returns:\n",
        "    tensor: Intersection over Union scores for each example.\n",
        "    \"\"\"\n",
        "\n",
        "    if box_format == \"midpoint\":\n",
        "        # Calculate coordinates of top-left (x1, y1) and bottom-right (x2, y2).\n",
        "        box1_x1 = boxes_preds[..., 0:1] - boxes_preds[..., 2:3] / 2\n",
        "        box1_y1 = boxes_preds[..., 1:2] - boxes_preds[..., 3:4] / 2\n",
        "        box1_x2 = boxes_preds[..., 0:1] + boxes_preds[..., 2:3] / 2\n",
        "        box1_y2 = boxes_preds[..., 1:2] + boxes_preds[..., 3:4] / 2\n",
        "\n",
        "        box2_x1 = boxes_labels[..., 0:1] - boxes_labels[..., 2:3] / 2\n",
        "        box2_y1 = boxes_labels[..., 1:2] - boxes_labels[..., 3:4] / 2\n",
        "        box2_x2 = boxes_labels[..., 0:1] + boxes_labels[..., 2:3] / 2\n",
        "        box2_y2 = boxes_labels[..., 1:2] + boxes_labels[..., 3:4] / 2\n",
        "    elif box_format == \"corners\":\n",
        "        # Extract coordinates for predicted boxes\n",
        "        box1_x1 = boxes_preds[..., 0:1]\n",
        "        box1_y1 = boxes_preds[..., 1:2]\n",
        "        box1_x2 = boxes_preds[..., 2:3]\n",
        "        box1_y2 = boxes_preds[..., 3:4]\n",
        "\n",
        "        # Extract coordinates for ground truth boxes\n",
        "        box2_x1 = boxes_labels[..., 0:1]\n",
        "        box2_y1 = boxes_labels[..., 1:2]\n",
        "        box2_x2 = boxes_labels[..., 2:3]\n",
        "        box2_y2 = boxes_labels[..., 3:4]\n",
        "\n",
        "    # Calculate coordinates of the intersection rectangle\n",
        "    x1 = torch.max(box1_x1, box2_x1)\n",
        "    y1 = torch.max(box1_y1, box2_y1)\n",
        "    x2 = torch.min(box1_x2, box2_x2)\n",
        "    y2 = torch.min(box1_y2, box2_y2)\n",
        "\n",
        "    # Compute the area of the intersection rectangle\n",
        "    intersection = (x2 - x1).clamp(0) * (y2 - y1).clamp(0)\n",
        "\n",
        "    # Calculate the areas of the predicted and ground truth boxes\n",
        "    box1_area = abs((box1_x2 - box1_x1) * (box1_y2 - box1_y1))\n",
        "    box2_area = abs((box2_x2 - box2_x1) * (box2_y2 - box2_y1))\n",
        "\n",
        "    # Calculate the Intersection over Union, adding a small epsilon to avoid division by zero\n",
        "    return intersection / (box1_area + box2_area - intersection + 1e-6)"
      ],
      "metadata": {
        "id": "cNiVz-Bj0flD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def non_max_suppression(bboxes, iou_threshold, threshold, box_format=\"corners\"):\n",
        "    \"\"\"\n",
        "    Perform Non-Maximum Suppression on a list of bounding boxes.\n",
        "\n",
        "    Parameters:\n",
        "    bboxes (list): List of bounding boxes, each represented as [class_pred, prob_score, x1, y1, x2, y2].\n",
        "    iou_threshold (float): IoU threshold to determine correct predicted bounding boxes.\n",
        "    threshold (float): Threshold to discard predicted bounding boxes (independent of IoU).\n",
        "    box_format (str): \"midpoint\" or \"corners\" to specify the format of bounding boxes.\n",
        "\n",
        "    Returns:\n",
        "    list: List of bounding boxes after performing NMS with a specific IoU threshold.\n",
        "    \"\"\"\n",
        "\n",
        "    # Check the data type of the input parameter\n",
        "    assert type(bboxes) == list\n",
        "\n",
        "    # Filter predicted bounding boxes based on probability threshold\n",
        "    bboxes = [box for box in bboxes if box[1] > threshold]\n",
        "\n",
        "    # Sort bounding boxes by probability in descending order\n",
        "    bboxes = sorted(bboxes, key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    # List to store bounding boxes after NMS\n",
        "    bboxes_after_nms = []\n",
        "\n",
        "    # Continue looping until the list of bounding boxes is empty\n",
        "    while bboxes:\n",
        "        # Get the bounding box with the highest probability\n",
        "        chosen_box = bboxes.pop(0)\n",
        "\n",
        "        # Remove bounding boxes with IoU greater than the specified threshold with the chosen box\n",
        "        bboxes = [\n",
        "            box for box in bboxes\n",
        "            if box[0] != chosen_box[0] or intersection_over_union(\n",
        "                torch.tensor(chosen_box[2:]),\n",
        "                torch.tensor(box[2:]),\n",
        "                box_format=box_format) < iou_threshold\n",
        "        ]\n",
        "\n",
        "        # Add the chosen bounding box to the list after NMS\n",
        "        bboxes_after_nms.append(chosen_box)\n",
        "\n",
        "    return bboxes_after_nms"
      ],
      "metadata": {
        "id": "bH7_SrJt1QsJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def mean_average_precision(pred_boxes, true_boxes, iou_threshold=0.5, box_format=\"midpoint\", num_classes=20):\n",
        "    \"\"\"\n",
        "    Calculate the mean average precision (mAP).\n",
        "\n",
        "    Parameters:\n",
        "    pred_boxes (list): A list containing predicted bounding boxes with each\n",
        "                       box defined as [train_idx, class_pred, prob_score, x1, y1, x2, y2].\n",
        "    true_boxes (list): Similar to pred_boxes but containing information about true boxes.\n",
        "    iou_threshold (float): IoU threshold, where predicted boxes are considered correct.\n",
        "    box_format (str): \"midpoint\" or \"corners\" used to specify the format of the boxes.\n",
        "    num_classes (int): Number of classes.\n",
        "\n",
        "    Returns:\n",
        "    float: The mAP value across all classes with a specific IoU threshold.\n",
        "    \"\"\"\n",
        "\n",
        "    # List to store mAP for each class\n",
        "    average_precisions = []\n",
        "    epsilon = 1e-6\n",
        "\n",
        "    for c in range(num_classes):\n",
        "        detections = []\n",
        "        ground_truths = []\n",
        "\n",
        "        # Iterate through all predictions and targets, and only add those belonging to the current class 'c'.\n",
        "        for detection in pred_boxes:\n",
        "            if detection[1] == c:\n",
        "                detections.append(detection)\n",
        "\n",
        "        for true_box in true_boxes:\n",
        "            if true_box[1] == c:\n",
        "                ground_truths.append(true_box)\n",
        "\n",
        "        # Find the number of boxes for each training example.\n",
        "        amount_bboxes = Counter([gt[0] for gt in ground_truths])\n",
        "        for key, val in amount_bboxes.items():\n",
        "            amount_bboxes[key] = torch.zeros(val)\n",
        "\n",
        "        # Sort by box probability\n",
        "        detections.sort(key=lambda x: x[2], reverse=True)\n",
        "        TP = torch.zeros((len(detections)))\n",
        "        FP = torch.zeros((len(detections)))\n",
        "        total_true_bboxes = len(ground_truths)\n",
        "\n",
        "        # If there are no ground truth boxes for this class, it can be safely skipped\n",
        "        if total_true_bboxes == 0:\n",
        "            continue\n",
        "\n",
        "        for detection_idx, detection in enumerate(detections):\n",
        "            ground_truth_img = [\n",
        "                bbox for bbox in ground_truths if bbox[0] == detection[0]\n",
        "            ]\n",
        "\n",
        "            num_gts = len(ground_truth_img)\n",
        "            best_iou = 0\n",
        "\n",
        "            for idx, gt in enumerate(ground_truth_img):\n",
        "                iou = intersection_over_union(\n",
        "                    torch.tensor(detection[3:]),\n",
        "                    torch.tensor(gt[3:]),\n",
        "                    box_format=box_format\n",
        "                )\n",
        "\n",
        "                if iou > best_iou:\n",
        "                    best_iou = iou\n",
        "                    best_gt_idx = idx\n",
        "\n",
        "            if best_iou > iou_threshold:\n",
        "                if amount_bboxes[detection[0]][best_gt_idx] == 0:  # True positive\n",
        "                    TP[detection_idx] = 1\n",
        "                    amount_bboxes[detection[0]][best_gt_idx] = 1\n",
        "                else:  # False positive\n",
        "                    FP[detection_idx] = 1\n",
        "            else:\n",
        "                FP[detection_idx] = 1\n",
        "\n",
        "        # Calculate cumulative TP and FP\n",
        "        TP_cumsum = torch.cumsum(TP, dim=0)\n",
        "        FP_cumsum = torch.cumsum(FP, dim=0)\n",
        "        precisions = torch.divide(TP_cumsum, TP_cumsum + FP_cumsum + epsilon)\n",
        "        recalls = torch.cat((torch.tensor([0]), precisions))\n",
        "\n",
        "        average_precisions.append(torch.trapz(precisions, recalls))\n",
        "\n",
        "    return sum(average_precisions) / len(average_precisions) if average_precisions else 0"
      ],
      "metadata": {
        "id": "-FZKaKHn1olJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from collections import Counter\n",
        "\n",
        "# Cấu hình kiến trúc\n",
        "architecture_config = [\n",
        "    (7, 64, 2, 3),     # Khối tích chập 1\n",
        "    \"M\",               # Lớp Max-pooling 1\n",
        "    (3, 192, 1, 1),   # Khối tích chập 2\n",
        "    \"M\",               # Lớp Max-pooling 2\n",
        "    (1, 128, 1, 0),   # Khối tích chập 3\n",
        "    (3, 256, 1, 1),   # Khối tích chập 4\n",
        "    (1, 256, 1, 0),   # Khối tích chập 5\n",
        "    (3, 512, 1, 1),   # Khối tích chập 6\n",
        "    \"M\",               # Lớp Max-pooling 3\n",
        "    (3, 512, 1, 1),   # Khối tích chập 7\n",
        "    (3, 512, 1, 1),   # Khối tích chập 8\n",
        "    (3, 512, 1, 1),   # Khối tích chập 9\n",
        "    \"M\",               # Lớp Max-pooling 4\n",
        "    (3, 1024, 1, 1),  # Khối tích chập 10\n",
        "    \"M\",               # Lớp Max-pooling 5\n",
        "    (3, 1024, 1, 1),  # Khối tích chập 11\n",
        "]\n",
        "\n",
        "# Định nghĩa khối CNN\n",
        "class CNNBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, **kwargs):\n",
        "        super(CNNBlock, self).__init__()\n",
        "        self.conv = nn.Conv2d(in_channels, out_channels, bias=False, **kwargs)\n",
        "        self.batchnorm = nn.BatchNorm2d(out_channels)\n",
        "        self.leakyrelu = nn.LeakyReLU(0.1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.leakyrelu(self.batchnorm(self.conv(x)))\n",
        "\n",
        "# Định nghĩa lớp YOLOv1\n",
        "class YoloV1(nn.Module):\n",
        "    def __init__(self, in_channels=3, **kwargs):\n",
        "        super(YoloV1, self).__init__()\n",
        "        self.in_channels = in_channels\n",
        "        self.architecture_config = kwargs.get('architecture_config', [])\n",
        "        self.conv_layers = self.create_conv_layers(self.architecture_config)\n",
        "        self.fc_layers = self.create_fc_layers(**kwargs)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv_layers(x)\n",
        "        return self.fc_layers(torch.flatten(x, start_dim=1))\n",
        "\n",
        "    def create_conv_layers(self, architecture):\n",
        "        layers = []\n",
        "        in_channels = self.in_channels\n",
        "\n",
        "        for x in architecture:\n",
        "            if isinstance(x, tuple):\n",
        "                layers += [\n",
        "                    CNNBlock(\n",
        "                        in_channels, x[1],\n",
        "                        kernel_size=x[0],\n",
        "                        stride=x[2],\n",
        "                        padding=x[3]\n",
        "                    )\n",
        "                ]\n",
        "                in_channels = x[1]\n",
        "            elif x == \"M\":\n",
        "                layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def create_fc_layers(self, split_size, num_boxes, num_classes):\n",
        "        return nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(1024 * split_size * split_size, 4096),\n",
        "            nn.Dropout(0.0),\n",
        "            nn.LeakyReLU(0.1),\n",
        "            nn.Linear(4096, split_size * split_size * (num_boxes * 5 + num_classes))\n",
        "        )\n",
        "\n",
        "# Tạo mô hình với các thông số cụ thể\n",
        "model = YoloV1(architecture_config=architecture_config, split_size=7, num_boxes=2, num_classes=20)\n",
        "print(model)"
      ],
      "metadata": {
        "id": "-C1oQ5Bk143u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class YoloLoss(nn.Module):\n",
        "    \"\"\"\n",
        "    Tính toán loss cho mô hình YOLO (v1).\n",
        "    \"\"\"\n",
        "    def __init__(self, S=7, B=2, C=20):\n",
        "        super(YoloLoss, self).__init__()\n",
        "        self.mse = nn.MSELoss(reduction=\"sum\")\n",
        "        self.S = S\n",
        "        self.B = B\n",
        "        self.C = C\n",
        "        self.lambda_noobj = 0.5\n",
        "        self.lambda_coord = 5\n",
        "\n",
        "    def forward(self, predictions, target):\n",
        "        # Reshape dự đoán thành định dạng (BATCH_SIZE, S, S, C + B*5)\n",
        "        predictions = predictions.reshape(-1, self.S, self.S, self.C + self.B * 5)\n",
        "\n",
        "        # Tính toán IoU cho các bounding box\n",
        "        iou_b1 = self.intersection_over_union(predictions[..., 21:25], target[..., 21:25])\n",
        "        iou_b2 = self.intersection_over_union(predictions[..., 26:30], target[..., 21:25])\n",
        "\n",
        "        iou = torch.cat((iou_b1.unsqueeze(0), iou_b2.unsqueeze(0)), dim=0)\n",
        "\n",
        "        # Lấy box có IoU cao nhất\n",
        "        iou_maxes, bestbox = torch.max(iou, dim=0)\n",
        "        exists_box = target[..., 20].unsqueeze(3)  # đại diện cho obj 1j trong tài liệu\n",
        "\n",
        "        # Tính toán box_targets\n",
        "        box_targets = exists_box * target[..., 21:25]\n",
        "        box_predictions = exists_box * (\n",
        "            bestbox * predictions[..., 26:30] +\n",
        "            (1 - bestbox) * predictions[..., 21:25]\n",
        "        )\n",
        "\n",
        "        # Tính toán loss cho box\n",
        "        box_loss = self.mse(\n",
        "            torch.flatten(box_predictions, end_dim=-2),\n",
        "            torch.flatten(box_targets, end_dim=-2)\n",
        "        )\n",
        "\n",
        "        # ================= #\n",
        "        #   FOR OBJECT LOSS  #\n",
        "        # ================= #\n",
        "        pred_box = (\n",
        "            bestbox * predictions[..., 25:26] +\n",
        "            (1 - bestbox) * predictions[..., 21:21]\n",
        "        )\n",
        "        object_loss = self.mse(\n",
        "            torch.flatten(exists_box * pred_box),\n",
        "            torch.flatten(exists_box * target[..., 20:21])\n",
        "        )\n",
        "\n",
        "        # =================== #\n",
        "        #   FOR NO OBJECT LOSS  #\n",
        "        # =================== #\n",
        "        no_object_loss = self.mse(\n",
        "            torch.flatten((1 - exists_box) * predictions[..., 25:26]),\n",
        "            torch.flatten((1 - exists_box) * target[..., 20:21])\n",
        "        )\n",
        "\n",
        "        # ================= #\n",
        "        #      FOR CLASS LOSS      #\n",
        "        # ================= #\n",
        "        class_loss = self.mse(\n",
        "            torch.flatten(exists_box * predictions[..., :20]),\n",
        "            torch.flatten(exists_box * target[..., :20])\n",
        "        )\n",
        "\n",
        "        # Tính toán loss cuối cùng bằng cách kết hợp các thành phần trên.\n",
        "        loss = (\n",
        "            self.lambda_coord * box_loss +  # First term\n",
        "            object_loss +                    # Second term\n",
        "            self.lambda_noobj * no_object_loss +  # Third term\n",
        "            class_loss                        # Fourth term\n",
        "        )\n",
        "        return loss\n"
      ],
      "metadata": {
        "id": "l9fF6ZNV2UMY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import albumentations as A\n",
        "\n",
        "# Định nghĩa các hằng số cho kích thước\n",
        "WIDTH = 448\n",
        "HEIGHT = 448\n",
        "\n",
        "# Hàm để lấy các biến đổi cho tập huấn luyện\n",
        "def get_train_transforms():\n",
        "    return A.Compose([\n",
        "        A.OneOf([\n",
        "            A.HueSaturationValue(hue_shift_limit=0.2, sat_shift_limit=0.2, val_shift_limit=0.2, p=0.9),\n",
        "            A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=0.9)\n",
        "        ]),\n",
        "        A.ToGray(p=0.01),\n",
        "        A.HorizontalFlip(p=0.2),\n",
        "        A.VerticalFlip(p=0.2),\n",
        "    ])\n",
        "\n",
        "# Hàm để lấy các biến đổi cho tập xác thực\n",
        "def get_valid_transforms():\n",
        "    return A.Compose([\n",
        "        A.Resize(height=WIDTH, width=WIDTH, p=1.0),\n",
        "        A.ToTensorV2(p=1.0),\n",
        "        A.BboxParams(format='yolo', min_area=0, label_fields=['labels'])\n",
        "    ])\n",
        "\n",
        "# Thiết lập ngẫu nhiên cho khả năng tái tạo\n",
        "seed = 123\n",
        "torch.manual_seed(seed)\n",
        "\n",
        "# Các tham số và cấu hình\n",
        "LEARNING_RATE = 2e-5\n",
        "DEVICE = \"cuda\"\n",
        "BATCH_SIZE = 16\n",
        "EPOCHS = 300\n",
        "NUM_WORKERS = 2\n",
        "PIN_MEMORY = True\n",
        "LOAD_MODEL = False\n",
        "LOAD_MODEL_FILE = \"yolov1.pth.tar\"\n",
        "\n",
        "# Định nghĩa ánh xạ lớp\n",
        "class_mapping = {\n",
        "    'aeroplane': 0,\n",
        "    'bicycle': 1,\n",
        "    'bird': 2,\n",
        "    'boat': 3,\n",
        "    'bottle': 4,\n",
        "    'bus': 5,\n",
        "    'car': 6,\n",
        "    'cat': 7,\n",
        "    'chair': 8,\n",
        "    'cow': 9,\n",
        "    'diningtable': 10,\n",
        "    'dog': 11,\n",
        "    'horse': 12,\n",
        "    'motorbike': 13,\n",
        "    'person': 14,\n",
        "    'pottedplant': 15,\n",
        "    'sheep': 16,\n",
        "    'sofa': 17,\n",
        "    'train': 18,\n",
        "    'tvmonitor': 19\n",
        "}"
      ],
      "metadata": {
        "id": "f-aq6gKz4k5T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "def train_fn(train_loader, model, optimizer, loss_fn, epoch):\n",
        "    mean_loss = []\n",
        "    mean_AP = []\n",
        "\n",
        "    total_batches = len(train_loader)\n",
        "    display_interval = total_batches // 5  # Cập nhật sau 20% của tổng số batch.\n",
        "\n",
        "    for batch_idx, (x, y) in enumerate(train_loader):\n",
        "        x = x.to(DEVICE)\n",
        "        y = y.to(DEVICE)\n",
        "\n",
        "        # Tiến hành dự đoán\n",
        "        out = model(x)\n",
        "        loss = loss_fn(out, y)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        pred_boxes, true_boxes = get_bboxes_training(out, y, iou_threshold=0.4)\n",
        "        mAP = mean_average_precision(pred_boxes, true_boxes, iou_threshold=0.4, box_format=\"midpoint\")\n",
        "\n",
        "        mean_loss.append(loss.item())\n",
        "        mean_AP.append(mAP.item())\n",
        "\n",
        "        if batch_idx % display_interval == 0 or batch_idx == total_batches - 1:\n",
        "            print(f\"Epoch: {epoch}: Iter: {batch_idx}/{total_batches}: Loss: {loss.item():.3f}  mAP: {mAP.item():.3f}\")\n",
        "\n",
        "    avg_loss = sum(mean_loss) / len(mean_loss)\n",
        "    avg_mAP = sum(mean_AP) / len(mean_AP)\n",
        "    print(f\"Train Loss: {avg_loss:.3f}  mAP: {avg_mAP:.3f}\")\n",
        "\n",
        "    return avg_mAP\n",
        "\n",
        "\n",
        "def test_fn(test_loader, model, loss_fn, epoch):\n",
        "    model.eval()\n",
        "    mean_loss = []\n",
        "    mean_AP = []\n",
        "\n",
        "    for batch_idx, (x, y) in enumerate(test_loader):\n",
        "        x = x.to(DEVICE)\n",
        "        y = y.to(DEVICE)\n",
        "\n",
        "        # Tiến hành dự đoán\n",
        "        out = model(x)\n",
        "        loss = loss_fn(out, y)\n",
        "\n",
        "        pred_boxes, true_boxes = get_bboxes_training(out, y, iou_threshold=0.4)\n",
        "        mAP = mean_average_precision(pred_boxes, true_boxes, iou_threshold=0.4, box_format=\"midpoint\")\n",
        "\n",
        "        mean_loss.append(loss.item())\n",
        "        mean_AP.append(mAP.item())\n",
        "\n",
        "    avg_loss = sum(mean_loss) / len(mean_loss)\n",
        "    avg_mAP = sum(mean_AP) / len(mean_AP)\n",
        "    print(f\"Test Loss: {avg_loss:.3f}  mAP: {avg_mAP:.3f}\")\n",
        "\n",
        "    model.train ()\n",
        "\n",
        "    return avg_mAP"
      ],
      "metadata": {
        "id": "SdCCYAm34-ci"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "from torch.utils.data import DataLoader, SubsetRandomSampler\n",
        "\n",
        "def plot_image_with_labels(image, ground_truth_boxes, predicted_boxes, class_mapping):\n",
        "    \"\"\"Draw both ground truth and predicted bounding boxes on an image, with labels.\"\"\"\n",
        "    inverted_class_mapping = {v: k for k, v in class_mapping.items()}\n",
        "\n",
        "    # Convert the image to a numpy array and get its dimensions\n",
        "    im = np.array(image)\n",
        "    height, width, _ = im.shape\n",
        "\n",
        "    # Create a figure and axis for plotting\n",
        "    fig, ax = plt.subplots(1)\n",
        "    ax.imshow(im)\n",
        "\n",
        "    # Plot each ground truth box in green\n",
        "    for box in ground_truth_boxes:\n",
        "        label_index = box[0]\n",
        "        box = box[1:]\n",
        "        upper_left_x = box[0] - box[2] / 2\n",
        "        upper_left_y = box[1] - box[3] / 2\n",
        "        rect = patches.Rectangle((upper_left_x * width, upper_left_y * height), box[2] * width, box[3] * height,\n",
        "                                 linewidth=1, edgecolor=\"green\", facecolor=\"none\")\n",
        "        ax.add_patch(rect)\n",
        "\n",
        "        class_name = inverted_class_mapping.get(label_index, \"Unknown\")\n",
        "        ax.text(upper_left_x * width, upper_left_y * height, class_name, fontsize=12,\n",
        "                bbox=dict(facecolor='green', alpha=0.2))\n",
        "\n",
        "    # Plot each predicted box in red\n",
        "    for box in predicted_boxes:\n",
        "        label_index = box[0]\n",
        "        box = box[1:]\n",
        "        upper_left_x = box[0] - box[2] / 2\n",
        "        upper_left_y = box[1] - box[3] / 2\n",
        "        rect = patches.Rectangle((upper_left_x * width, upper_left_y * height), box[2] * width, box[3] * height,\n",
        "                                 linewidth=1, edgecolor=\"red\", facecolor=\"none\")\n",
        "        ax.add_patch(rect)\n",
        "\n",
        "        class_name = inverted_class_mapping.get(label_index, \"Unknown\")\n",
        "        ax.text(upper_left_x * width, upper_left_y * height, class_name, fontsize=12,\n",
        "                bbox=dict(facecolor='red', alpha=0.2))\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "def test():\n",
        "    # Create a YOLO model object with specific hyperparameters\n",
        "    model = YoloV1(split_size=7, num_boxes=2, num_classes=20).to(DEVICE)\n",
        "\n",
        "    # Load saved model weights and optimizer information from a file, if applicable\n",
        "    if LOAD_MODEL:\n",
        "        model.load_state_dict(torch.load(LOAD_MODEL_FILE)['state_dict'])\n",
        "\n",
        "    # Prepare the test dataset and DataLoader for model evaluation\n",
        "    test_dataset = CustomVOCDataSet(root='./data/', image_set='val', download=True)\n",
        "    test_dataset.init_config_yolo(class_mapping=class_mapping, custom_transforms=get_valid_transforms())\n",
        "    test_loader = DataLoader(dataset=test_dataset, batch_size=BATCH_SIZE,\n",
        "                             num_workers=NUM_WORKERS, pin_memory=PIN_MEMORY,\n",
        "                             shuffle=False, drop_last=False)\n",
        "\n",
        "    model.eval()\n",
        "    # Iterate over the test dataset and process each batch\n",
        "    for x, y in test_loader:\n",
        "        x = x.to(DEVICE)\n",
        "        out = model(x)\n",
        "\n",
        "        # Convert model output to bounding boxes and apply non-max suppression\n",
        "        pred_boxes = cellboxes_to_boxes(out)\n",
        "        gt_boxes = cellboxes_to_boxes(y)\n",
        "\n",
        "        # Plot the first 8 images with their ground truth and predicted bounding boxes\n",
        "        for idx in range(8):\n",
        "            pred_box = non_max_suppression(pred_boxes[idx], iou_threshold=0.5, box_format=\"midpoint\")\n",
        "            gt_box = non_max_suppression(gt_boxes[idx], iou_threshold=0.5, box_format=\"midpoint\")\n",
        "\n",
        "            image = x[idx].permute(1, 2, 0).cpu().detach().numpy() * 255\n",
        "            plot_image_with_labels(image, gt_box, pred_box, class_mapping)\n",
        "\n",
        "        break  # Stop after processing the first batch\n",
        "\n",
        "# Main function to train the model\n",
        "def train():\n",
        "    # Initialize model, optimizer, loss\n",
        "    model = YoloV1(split_size=7, num_boxes=2, num_classes=20).to(DEVICE)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
        "    loss_fn = YoloLoss()\n",
        "\n",
        "    # Load checkpoint if necessary\n",
        "    if LOAD_MODEL:\n",
        "        load_checkpoint(torch.load(LOAD_MODEL_FILE), model, optimizer)\n",
        "\n",
        "    # Create the full dataset\n",
        "    train_dataset = CustomVOCDataSet(root='./data/', year='2012', image_set='train', download=True)\n",
        "    train_dataset.init_config_yolo(class_mapping=class_mapping, custom_transforms=get_train_transforms())\n",
        "\n",
        "    testval_dataset = CustomVOCDataSet(root='./data/', year='2012', image_set='val', download=True)\n",
        "    testval_dataset.init_config_yolo(class_mapping=class_mapping, custom_transforms=get_valid_transforms())\n",
        "\n",
        "    # Split dataset into train, validation, and test sets using indices\n",
        "    dataset_size = len(testval_dataset)\n",
        "    val_size = int(0.15 * dataset_size)\n",
        "    test_size = dataset_size - val_size\n",
        "\n",
        "    val_indices = list(range(val_size))\n",
        "    test_indices = list(range(val_size, val_size + test_size))\n",
        "\n",
        "    # Create samplers\n",
        "    val_sampler = SubsetRandomSampler(val_indices)\n",
        "    test_sampler = SubsetRandomSampler(test_indices)\n",
        "\n",
        "    # Create DataLoaders using samplers\n",
        "    train_loader = DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE,\n",
        "                              num_workers=NUM_WORKERS, pin_memory=PIN_MEMORY, drop_last=True)\n",
        "\n",
        "    val_loader = DataLoader(dataset=testval_dataset, batch_size=BATCH_SIZE,\n",
        "                            num_workers=NUM_WORKERS, pin_memory=PIN_MEMORY, sampler=val_sampler)\n",
        "\n",
        "    test_loader = DataLoader(dataset=testval_dataset, batch_size=BATCH_SIZE,\n",
        "                             num_workers=NUM_WORKERS, pin_memory=PIN_MEMORY, sampler=test_sampler)\n",
        "\n",
        "    best_mAP_train = 0\n",
        "    best_mAP_val = 0\n",
        "    best_mAP_test = 0\n",
        "\n",
        "    # Training loop\n",
        "    for epoch in range(EPOCHS):\n",
        "        train_mAP = train_fn(train_loader, model, optimizer, loss_fn, epoch)\n",
        "        val_mAP = val_test_fn(val_loader, model, loss_fn, epoch)\n",
        "        test_mAP = val_test_fn(test_loader, model, loss_fn, epoch, is_test=True)\n",
        "\n",
        "        # Update best mAP values\n",
        "        if train_mAP > best_mAP_train:\n",
        "            best_mAP_train = train_mAP\n",
        "        if val_mAP > best_mAP_val:\n",
        "            best_mAP_val = val_mAP\n",
        "        if test_mAP > best_mAP_test:\n",
        "            best_mAP_test = test_mAP\n",
        "\n",
        "    print(f\"Best Train mAP: {best_mAP_train:.3f}\")\n",
        "    print(f\"Best Val mAP: {best_mAP_val:.3f}\")\n",
        "    print(f\"Best Test mAP: {best_mAP_test:.3f}\")\n",
        "\n",
        "# Chạy hàm train\n",
        "if __name__ == \"__main__\":\n",
        "    train()"
      ],
      "metadata": {
        "id": "sqP1h6Hr5IRQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}