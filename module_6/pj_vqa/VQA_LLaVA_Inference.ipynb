{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## **0. Download dataset**\n",
        "**Note:** If you can't download using gdown due to limited number of downloads, please download it manually and upload it to your drive, then copy it from the drive to colab.\n",
        "```python\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "!cp /path/to/dataset/on/your/drive .\n",
        "```"
      ],
      "metadata": {
        "id": "l4uP9QoFOv71"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# https://drive.google.com/file/d/1kc6XNqHZJg27KeBuoAoYj70_1rT92191/view?usp=sharing\n",
        "!gdown --id 1kc6XNqHZJg27KeBuoAoYj70_1rT92191"
      ],
      "metadata": {
        "id": "nUWtG4WEYvJL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -q vqa_coco_dataset.zip"
      ],
      "metadata": {
        "id": "5QIMoAGj9dU3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **1. Import libraries**"
      ],
      "metadata": {
        "id": "HSobzBafyQUD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Bx8iu9jOssW"
      },
      "outputs": [],
      "source": [
        "!pip install git+https://github.com/huggingface/transformers.git\n",
        "!pip install bitsandbytes==0.45.0\n",
        "!pip install accelerate==1.2.1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from transformers import LlavaForConditionalGeneration\n",
        "from transformers import AutoProcessor\n",
        "from transformers import BitsAndBytesConfig\n",
        "from transformers import GenerationConfig\n",
        "from PIL import Image"
      ],
      "metadata": {
        "id": "_wsvjOc-ySZV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **2. Read dataset**"
      ],
      "metadata": {
        "id": "nZPUymHXP9eH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = []\n",
        "train_set_path = './vaq2.0.TrainImages.txt'\n",
        "\n",
        "with open(train_set_path, \"r\") as f:\n",
        "    lines = f.readlines()\n",
        "    for line in lines:\n",
        "        temp = line.split('\\t')\n",
        "        qa = temp[1].split('?')\n",
        "\n",
        "        if len(qa) == 3:\n",
        "            answer = qa[2].strip()\n",
        "        else:\n",
        "            answer = qa[1].strip()\n",
        "\n",
        "        data_sample = {\n",
        "            'image_path': temp[0][:-2],\n",
        "            'question': qa[0] + '?',\n",
        "            'answer': answer\n",
        "        }\n",
        "        train_data.append(data_sample)"
      ],
      "metadata": {
        "id": "CNCjyy_JPm4T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_data = []\n",
        "val_set_path = './vaq2.0.DevImages.txt'\n",
        "\n",
        "with open(val_set_path, \"r\") as f:\n",
        "    lines = f.readlines()\n",
        "    for line in lines:\n",
        "        temp = line.split('\\t')\n",
        "        qa = temp[1].split('?')\n",
        "\n",
        "        if len(qa) == 3:\n",
        "            answer = qa[2].strip()\n",
        "        else:\n",
        "            answer = qa[1].strip()\n",
        "\n",
        "        data_sample = {\n",
        "            'image_path': temp[0][:-2],\n",
        "            'question': qa[0] + '?',\n",
        "            'answer': answer\n",
        "        }\n",
        "        val_data.append(data_sample)"
      ],
      "metadata": {
        "id": "eIXbs0zW9lh5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data = []\n",
        "test_set_path = './vaq2.0.TestImages.txt'\n",
        "\n",
        "with open(test_set_path, \"r\") as f:\n",
        "    lines = f.readlines()\n",
        "    for line in lines:\n",
        "        temp = line.split('\\t')\n",
        "        qa = temp[1].split('?')\n",
        "\n",
        "        if len(qa) == 3:\n",
        "            answer = qa[2].strip()\n",
        "        else:\n",
        "            answer = qa[1].strip()\n",
        "\n",
        "        data_sample = {\n",
        "            'image_path': temp[0][:-2],\n",
        "            'question': qa[0] + '?',\n",
        "            'answer': answer\n",
        "        }\n",
        "        test_data.append(data_sample)"
      ],
      "metadata": {
        "id": "l7IJ3YUf9mCU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **3. Create VQA model**"
      ],
      "metadata": {
        "id": "_FNZ3rVNQP6A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "quantization_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_compute_dtype=torch.float16\n",
        ")\n",
        "\n",
        "model_id = None\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "processor = AutoProcessor.from_pretrained(model_id)\n",
        "model = LlavaForConditionalGeneration.from_pretrained(model_id,\n",
        "                                                      quantization_config=quantization_config,\n",
        "                                                      device_map=device)"
      ],
      "metadata": {
        "id": "hqpPqDKuQUTq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **4. Create prompt**"
      ],
      "metadata": {
        "id": "SvvlRbPPzHj-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_prompt(question):\n",
        "  prompt = f\"\"\" ### INSTRUCTION:\n",
        "Your task is to answer the question based on the given image. You can\n",
        "  only answer ’yes ’ or ’no ’.\n",
        "### USER : <image >\n",
        "{question}\n",
        "### ASSISTANT:\"\"\"\n",
        "    return None"
      ],
      "metadata": {
        "id": "OospUDWQDj_Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"what is this about?\"\n",
        "create_prompt(question)"
      ],
      "metadata": {
        "id": "vjciDOyfFpiX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **5. Inference**"
      ],
      "metadata": {
        "id": "-fspoY40CwKk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "generation_config = GenerationConfig(\n",
        "    max_new_tokens=10,\n",
        "    do_sample=True,\n",
        "    temperature=0.1,\n",
        "    top_p=0.95,\n",
        "    top_k=50,\n",
        "    eos_token_id=model.config.eos_token_id,\n",
        "    pad_token=model.config.pad_token_id,\n",
        ")"
      ],
      "metadata": {
        "id": "QyByEjy2DxZ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "idx = 0\n",
        "question = test_data[idx]['question']\n",
        "image_name = test_data[idx]['image_path']\n",
        "image_path = os.path.join('val2014-resised', image_name)\n",
        "label = test_data[idx]['answer']\n",
        "image = Image.open(image_path)\n",
        "\n",
        "prompt = create_prompt(question)\n",
        "inputs = processor(prompt,\n",
        "                   image,\n",
        "                   padding=True,\n",
        "                   return_tensors=\"pt\").to(device)\n",
        "\n",
        "output = model.generate(**inputs,\n",
        "                        generation_config=generation_config)\n",
        "generated_text = processor.decode(output[0],\n",
        "                                  skip_special_tokens=True)\n",
        "\n",
        "plt.imshow(image)\n",
        "plt.axis(\"off\")\n",
        "plt.show()\n",
        "print(f\"Question: {question}\")\n",
        "print(f\"Label: {label}\")\n",
        "print(f\"Prediction: {generated_text.split('### ASSISTANT:')[-1]}\")"
      ],
      "metadata": {
        "id": "6mhFS3a_Cvd6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}