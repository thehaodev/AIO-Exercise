{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## **1. Install and import bibraries**"
      ],
      "metadata": {
        "id": "620RrNMA0zBd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KJThim7I0bbY"
      },
      "outputs": [],
      "source": [
        "!pip install -qq datasets==2.16.1 evaluate==0.4.1 transformers[sentencepiece]==4.35.2\n",
        "!pip install -qq accelerate==0.26.1\n",
        "!apt install git-lfs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lNp81e0j0bbZ"
      },
      "outputs": [],
      "source": [
        "from huggingface_hub import notebook_login\n",
        "\n",
        "notebook_login()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tqdm.auto import tqdm\n",
        "import collections\n",
        "\n",
        "import torch\n",
        "\n",
        "from datasets import load_dataset\n",
        "from transformers import AutoTokenizer\n",
        "from transformers import AutoModelForQuestionAnswering\n",
        "from transformers import TrainingArguments\n",
        "from transformers import Trainer\n",
        "import evaluate\n",
        "\n",
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
      ],
      "metadata": {
        "id": "MDPFsKd57IUT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **2. Setup config**"
      ],
      "metadata": {
        "id": "vvVFIm1v8g-A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Sử dụng mô hình \"distilbert-base-uncased\"\n",
        "# làm mô hình checkpoint\n",
        "MODEL_NAME = \"distilbert-base-uncased\"\n",
        "\n",
        "# Độ dài tối đa cho mỗi đoạn văn bản\n",
        "# sau khi được xử lý\n",
        "MAX_LENGTH = 384\n",
        "\n",
        "# Khoảng cách giữa các điểm bắt đầu\n",
        "# của các đoạn văn bản liên tiếp\n",
        "STRIDE = 128"
      ],
      "metadata": {
        "id": "jp2v8dH_7qS8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **3. Setup Dataset**"
      ],
      "metadata": {
        "id": "dJNkTaHI10OF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **3.1. Download dataset**\n",
        "\n"
      ],
      "metadata": {
        "id": "pGgIfkD517uM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dmkW9oYV0bbZ"
      },
      "outputs": [],
      "source": [
        "# Download squad dataset từ HuggingFace\n",
        "DATASET_NAME = 'squad_v2'\n",
        "raw_datasets = load_dataset(DATASET_NAME)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **3.2. EDA dataset**"
      ],
      "metadata": {
        "id": "WNhMX8gd1-fi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pzCbJgRx0bbZ"
      },
      "outputs": [],
      "source": [
        "raw_datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-7y9hRDY0bbZ"
      },
      "outputs": [],
      "source": [
        "# Print các thông tin Context, Question, vaf Answer trong dataset\n",
        "print(\"Context: \", raw_datasets[\"train\"][0][\"context\"])\n",
        "print(\"Question: \", raw_datasets[\"train\"][0][\"question\"])\n",
        "print(\"Answer: \", raw_datasets[\"train\"][0][\"answers\"])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "non_answers = raw_datasets[\"train\"].filter(\n",
        "    lambda x: len(x['answers']['text']) > 0\n",
        ")"
      ],
      "metadata": {
        "id": "N95p1ws9WGUL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "non_answers[0]"
      ],
      "metadata": {
        "id": "Kpg5l35BWl8u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **3.3. Load tokenizer and run some examples**"
      ],
      "metadata": {
        "id": "c_A9MTHc2qzL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load tokenizer để run một số example\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)"
      ],
      "metadata": {
        "id": "gZZRFh322jDv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Lấy ra 1 example từ tập train\n",
        "context = raw_datasets[\"train\"][0][\"context\"]\n",
        "question = raw_datasets[\"train\"][0][\"question\"]"
      ],
      "metadata": {
        "id": "CHWxTD2YCcaK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sử dụng tokenizer để mã hóa dữ liệu đầu vào\n",
        "inputs = None"
      ],
      "metadata": {
        "id": "6LHW7Jv62nOB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V1f-1rWO0bba"
      },
      "outputs": [],
      "source": [
        "inputs.keys()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputs"
      ],
      "metadata": {
        "id": "xOP_A4nhynsq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.decode(inputs['input_ids'][0])"
      ],
      "metadata": {
        "id": "OqCAAWpxYIJp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **4. Tokenize dataset**"
      ],
      "metadata": {
        "id": "wm7eKipz3S3p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **4.1. Tokenize train set**"
      ],
      "metadata": {
        "id": "qYWD7qNM3aWK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "izc985ty0bbb"
      },
      "outputs": [],
      "source": [
        "def preprocess_training_examples(examples):\n",
        "    # Trích xuất danh sách câu hỏi từ examples và loại bỏ các khoảng trống dư thừa\n",
        "    questions = [q.strip() for q in examples[\"question\"]]\n",
        "\n",
        "    # Tiến hành mã hóa thông tin đầu vào sử dụng tokenizer\n",
        "    inputs = tokenizer(\n",
        "        questions,\n",
        "        examples[\"context\"],\n",
        "        max_length=MAX_LENGTH,\n",
        "        truncation=\"only_second\",\n",
        "        stride=STRIDE,\n",
        "        return_overflowing_tokens=True,\n",
        "        return_offsets_mapping=True,\n",
        "        padding=\"max_length\",\n",
        "    )\n",
        "\n",
        "    # Trích xuất offset_mapping từ inputs và loại bỏ nó ra khỏi inputs\n",
        "    offset_mapping = inputs.pop(\"offset_mapping\")\n",
        "\n",
        "    # Trích xuất sample_map từ inputs và loại bỏ nó ra khỏi inputs\n",
        "    sample_map = inputs.pop(\"overflow_to_sample_mapping\")\n",
        "\n",
        "    # Khởi tạo danh sách các vị trí bắt đầu và kết thúc của câu trả lời\n",
        "    start_positions = []\n",
        "    end_positions = []\n",
        "\n",
        "    # Duyệt qua danh sách offset_mapping\n",
        "    for i, offset in enumerate(offset_mapping):\n",
        "        sample_idx = sample_map[i]\n",
        "\n",
        "        # Trích xuất sequence_ids từ inputs\n",
        "        sequence_ids = inputs.sequence_ids(i)\n",
        "\n",
        "        # Xác định vị trí bắt đầu và kết thúc của ngữ cảnh\n",
        "        idx = 0\n",
        "        while sequence_ids[idx] != 1:\n",
        "            idx += 1\n",
        "        context_start = idx\n",
        "        while sequence_ids[idx] == 1:\n",
        "            idx += 1\n",
        "        context_end = idx - 1\n",
        "\n",
        "        # Trích xuất thông tin về câu trả lời cho mẫu này\n",
        "        answer = answers[sample_idx]\n",
        "        if len(answer[\"text\"]) > 0:\n",
        "            start_char = answer[\"answer_start\"][0]\n",
        "            end_char = start_char + len(answer[\"text\"][0])\n",
        "\n",
        "            # Nếu câu trả lời không hoàn toàn trong ngữ cảnh, gán NaN cho start_positions và end_positions\n",
        "            if offset[context_start][0] > start_char or offset[context_end][1] < end_char:\n",
        "                start_positions.append(0)\n",
        "                end_positions.append(0)\n",
        "            else:\n",
        "                start_positions.append(idx + 1)\n",
        "                end_positions.append(idx + 1)\n",
        "\n",
        "    # Thêm thông tin về vị trí bắt đầu và kết thúc vào inputs\n",
        "    inputs[\"start_positions\"] = start_positions\n",
        "    inputs[\"end_positions\"] = end_positions\n",
        "\n",
        "    return inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tPO99TKo0bbb"
      },
      "outputs": [],
      "source": [
        "# Tạo một biến train_dataset và gán cho nó giá trị sau khi áp dụng hàm preprocess_training_examples lên tập dữ liệu \"train\"\n",
        "# Bật chế độ xử lý theo từng batch bằng cách đặt batched=True\n",
        "# Loại bỏ các cột không cần thiết trong tập dữ liệu \"train\" bằng cách sử dụng remove_columns\n",
        "\n",
        "train_dataset = raw_datasets[\"train\"].map(\n",
        "    preprocess_training_examples,\n",
        "    batched=True,\n",
        "    remove_columns=raw_datasets[\"train\"].column_names,\n",
        ")\n",
        "\n",
        "# In ra độ dài của tập dữ liệu \"train\" ban đầu và độ dài của tập dữ liệu đã được xử lý (train_dataset)\n",
        "len(raw_datasets[\"train\"]), len(train_dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **4.2. Tokenize Val set**"
      ],
      "metadata": {
        "id": "bOxgKFwS3dQj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N3av3Eir0bbb"
      },
      "outputs": [],
      "source": [
        "def preprocess_validation_examples(examples):\n",
        "    # Chuẩn bị danh sách câu hỏi bằng cách\n",
        "    # loại bỏ khoảng trắng ở đầu và cuối mỗi câu hỏi\n",
        "    questions = [q.strip() for q in examples[\"question\"]]\n",
        "\n",
        "    # Sử dụng tokenizer để mã hóa các câu hỏi và văn bản liên quan\n",
        "    inputs = tokenizer(\n",
        "        questions,\n",
        "        examples=[\"context\"],\n",
        "        max_length=MAX_LENGTH,\n",
        "        truncation=\"only_second\",\n",
        "        stride=STRIDE,\n",
        "        return_overflowing_tokens=True,\n",
        "        return_offsets_mapping=True,\n",
        "        padding=\"max_length\",\n",
        "    )\n",
        "\n",
        "    # Lấy ánh xạ để ánh xạ lại ví dụ tham chiếu cho từng dòng trong inputs\n",
        "    sample_map = inputs.pop(\"overflow_to_sample_mapping\")\n",
        "    example_ids = []\n",
        "\n",
        "    # Xác định ví dụ tham chiếu cho mỗi dòng đầu vào và điều chỉnh ánh xạ offset\n",
        "    for i in range(len(inputs[\"input_ids\"])):\n",
        "        sample_idx = sample_map[i]\n",
        "        example_ids.append(examples[\"id\"][sample_idx])\n",
        "\n",
        "        sequence_ids = inputs.sequence_ids(i)\n",
        "        offset = inputs[\"offset_mapping\"][i]\n",
        "\n",
        "        # Loại bỏ các offset không phù hợp với sequence_ids\n",
        "        inputs[\"offset_mapping\"][i] = [\n",
        "            o if sequence_ids[k] == 1 else None\n",
        "            for k, o in enumerate(offset)\n",
        "        ]\n",
        "\n",
        "    # Thêm thông tin ví dụ tham chiếu vào đầu vào\n",
        "    inputs[\"example_id\"] = example_ids\n",
        "    return inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ma5GMl1N0bbb"
      },
      "outputs": [],
      "source": [
        "# Tạo một biến validation_dataset và gán giá trị bằng việc sử dụng dữ liệu từ raw_datasets[\"validation\"] sau khi áp dụng một hàm xử lý trước.\n",
        "validation_dataset = raw_datasets[\"validation\"].map(\n",
        "    preprocess_validation_examples,  # Gọi hàm preprocess_validation_examples để xử lý dữ liệu đầu vào.\n",
        "    batched=True,  # Xử lý dữ liệu theo từng batch.\n",
        "    remove_columns=raw_datasets[\"validation\"].column_names,  # Loại bỏ các cột không cần thiết từ dữ liệu ban đầu.\n",
        ")\n",
        "\n",
        "# In ra độ dài của raw_datasets[\"validation\"] và validation_dataset để so sánh.\n",
        "len(raw_datasets[\"validation\"]), len(validation_dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **5. Train model**"
      ],
      "metadata": {
        "id": "RFJIPH3052a7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hth3TqHG0bbc"
      },
      "outputs": [],
      "source": [
        "# Load model\n",
        "model = AutoModelForQuestionAnswering.from_pretrained(MODEL_NAME)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KAWl_kMx0bbh"
      },
      "outputs": [],
      "source": [
        "from transformers import TrainingArguments\n",
        "\n",
        "# Tạo đối tượng args là các tham số cho quá trình huấn luyện\n",
        "args = TrainingArguments(\n",
        "    output_dir=\"distilbert-finetuned-squadv2\",  # Thư mục lưu output\n",
        "    evaluation_strategy=\"no\",                     # Chế độ đánh giá không tự động sau mỗi epoch\n",
        "    save_strategy=\"epoch\",                        # Lưu checkpoint sau mỗi epoch\n",
        "    learning_rate=2e-5,                          # Tốc độ học\n",
        "    num_train_epochs=3,                          # Số epoch huấn luyện\n",
        "    weight_decay=0.01,                           # Giảm trọng lượng mô hình để tránh overfitting\n",
        "    fp16=True,                                   # Sử dụng kiểu dữ liệu half-precision để tối ưu tài nguyên\n",
        "    push_to_hub=True                             # Đẩy kết quả huấn luyện lên HuggingFace Hub\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pzg-E2PL0bbh"
      },
      "outputs": [],
      "source": [
        "# Khởi tạo một đối tượng Trainer để huấn luyện mô hình\n",
        "trainer = Trainer(\n",
        "    model=model,  # Sử dụng mô hình đã tạo trước đó\n",
        "    args=args,  # Các tham số và cấu hình huấn luyện\n",
        "    train_dataset=train_dataset,  # Sử dụng tập dữ liệu huấn luyện\n",
        "    eval_dataset=validation_dataset,  # Sử dụng tập dữ liệu đánh giá\n",
        "    tokenizer=tokenizer,  # Sử dụng tokenizer để xử lý văn bản\n",
        ")\n",
        "\n",
        "# Bắt đầu quá trình huấn luyện\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Gửi dữ liệu đào tạo lên Hub\n",
        "trainer.push_to_hub(commit_message=\"Training complete\")"
      ],
      "metadata": {
        "id": "HUsBLBOrBYJA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **6. Evaluate model**"
      ],
      "metadata": {
        "id": "LQfeQvDv9vAG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tải metric \"squad\" từ thư viện evaluate\n",
        "metric = evaluate.load(\"squad_v2\")"
      ],
      "metadata": {
        "id": "FM81jdGS-aqZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "N_BEST = 20 # Số lượng kết quả tốt nhất được lựa chọn sau khi dự đoán\n",
        "MAX_ANS_LENGTH = 30 # Độ dài tối đa cho câu trả lời dự đoán\n",
        "\n",
        "def compute_metrics(start_logits, end_logits, features, examples):\n",
        "    # Tạo một từ điển mặc định để ánh xạ mỗi ví dụ với danh sách các đặc trưng tương ứng\n",
        "    example_to_features = collections.defaultdict(list)\n",
        "    for idx, feature in enumerate(features):\n",
        "        example_to_features[feature['example_id']].append(idx)\n",
        "\n",
        "    predicted_answers = []\n",
        "    for example in tqdm(examples):\n",
        "        example_id = example['id']\n",
        "        context = example['context']\n",
        "        answers = []\n",
        "\n",
        "        # Lặp qua tất cả các đặc trưng liên quan đến ví dụ đó\n",
        "        for feature_index in example_to_features[example_id]:\n",
        "            start_logit = start_logits[feature_index]\n",
        "            end_logit = end_logits[feature_index]\n",
        "            offsets = features[feature_index]['offset_mapping']\n",
        "\n",
        "            # Lấy các chỉ số có giá trị lớn nhất cho start và end logits\n",
        "            start_indexes = np.argsort(start_logit)[-1 : -N_BEST - 1 : -1].tolist()\n",
        "            end_indexes = np.argsort(end_logit)[-1 : -N_BEST - 1 : -1].tolist()\n",
        "            for start_index in start_indexes:\n",
        "                for end_index in end_indexes:\n",
        "                    # Bỏ qua các câu trả lời không hoàn toàn nằm trong ngữ cảnh\n",
        "                    if offsets[start_index] is None or offsets[end_index] is None:\n",
        "                        continue\n",
        "                    # Bỏ qua các câu trả lời có độ dài > max_answer_length\n",
        "                    if end_index - start_index + 1 > MAX_ANS_LENGTH:\n",
        "                        continue\n",
        "\n",
        "                    # Tạo một câu trả lời mới\n",
        "                    answer = {\n",
        "                        'text': context[offsets[start_index][0] : offsets[end_index][1]],\n",
        "                        'logit_score': start_logit[start_index] + end_logit[end_index],\n",
        "                    }\n",
        "                    answers.append(answer)\n",
        "\n",
        "        # Chọn câu trả lời có điểm số tốt nhất\n",
        "        if len(answers) > 0:\n",
        "            best_answer = max(answers, key=lambda x: x['logit_score'])\n",
        "            answer_dict = {\n",
        "                'id': example_id,\n",
        "                'prediction_text': best_answer['text'],\n",
        "                'no_answer_probability': 1 - best_answer['logit_score']\n",
        "            }\n",
        "        else:\n",
        "            answer_dict = {\n",
        "                'id': example_id,\n",
        "                'prediction_text': '',\n",
        "                'no_answer_probability': 1.0\n",
        "            }\n",
        "        predicted_answers.append(answer_dict)\n",
        "\n",
        "    # Tạo danh sách câu trả lời lý thuyết từ các ví dụ\n",
        "    theoretical_answers = [\n",
        "        {'id': ex['id'], 'answers': ex['answers']} for ex in examples\n",
        "    ]\n",
        "    # Sử dụng metric.compute để tính toán các độ đo và trả về kết quả\n",
        "    return metric.compute(predictions=predicted_answers, references=theoretical_answers)"
      ],
      "metadata": {
        "id": "X58eJ8WG1H-u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Thực hiện dự đoán trên tập dữ liệu validation\n",
        "predictions, _, _ = trainer.predict(validation_dataset)\n",
        "\n",
        "# Lấy ra thông tin về các điểm bắt đầu và điểm kết thúc của câu trả lời dự đoán\n",
        "start_logits, end_logits = predictions\n",
        "\n",
        "# Tính toán các chỉ số đánh giá sử dụng hàm compute_metrics\n",
        "results = compute_metrics(\n",
        "    start_logits,\n",
        "    end_logits,\n",
        "    validation_dataset,\n",
        "    raw_datasets[\"validation\"]\n",
        ")\n",
        "results"
      ],
      "metadata": {
        "id": "Nw_hJd8E3sdK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **8. Load model from Hub**"
      ],
      "metadata": {
        "id": "oNW8B5LKAe4c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use a pipeline as a high-level helper\n",
        "from transformers import pipeline\n",
        "\n",
        "PIPELINE_NAME = 'question-answering'\n",
        "MODEL_NAME = 'thangduong0509/distilbert-finetuned-squadv2'\n",
        "pipe = pipeline(PIPELINE_NAME, model=MODEL_NAME)"
      ],
      "metadata": {
        "id": "_WPOzycUAgCj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "INPUT_QUESTION = 'where is the highest mountain in solar system located'\n",
        "INPUT_CONTEXT = 'The highest mountain and volcano in the Solar System is on the planet Mars. It is called Olympus Mons and is 16 miles (24 kilometers) high which makes it about three times higher than Mt. Everest.'\n",
        "pipe(question=INPUT_QUESTION, context=INPUT_CONTEXT)"
      ],
      "metadata": {
        "id": "rHjmw4tGAluY"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}